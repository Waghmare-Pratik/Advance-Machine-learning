{
 "cells": [
  {
   "cell_type": "raw",
   "id": "13e400c7-ceec-4043-8cef-f0d4d820173c",
   "metadata": {},
   "source": [
    "Reinforcement Learning\n",
    "A. Calculating Reward \n",
    "B. Discounted Reward\n",
    "C. Calculating Optimal quantities \n",
    "D. Implementing Q Learning e\n",
    "E. Setting up an Optimal Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec6659b-ccb9-4f01-8879-3910bb6e1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "import random\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf727861-392a-4daa-be30-ccb2f29e4146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleEnvironment:\n",
    "    def __init__(self):\n",
    "        self.steps_left = 20\n",
    "\n",
    "    def get_observation(self) -> List[float]:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "    def get_action(self) -> List[int]:\n",
    "        return [0, 1]\n",
    "\n",
    "    def is_done(self) -> bool:\n",
    "        return self.steps_left == 0\n",
    "\n",
    "    def action(self, action: int) -> float:\n",
    "        if self.is_done():\n",
    "            raise Exception(\"Game is over\")\n",
    "        self.steps_left -= 1\n",
    "        return random.random()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a321c585-8a3d-4912-bf5b-9be6fa489f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.total_reward = 0.0\n",
    "\n",
    "    def step(self, env: SampleEnvironment):\n",
    "        current_obs = env.get_observation()\n",
    "        print(\"Observation {}\".format(current_obs))\n",
    "        actions = env.get_action()\n",
    "        print(\"Action {}\".format(actions))\n",
    "        reward = env.action(random.choice(actions))\n",
    "        self.total_reward += reward\n",
    "        print(\"Reward {}\".format(self.total_reward))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca68792d-9374-40cf-b48a-76b5a24b4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 0.3864969361761117\n",
      "step 2\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 0.9155029018337156\n",
      "step 3\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 1.7603935906012218\n",
      "step 4\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 2.061011064234271\n",
      "step 5\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 2.9152275043930036\n",
      "step 6\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 3.3072241161098384\n",
      "step 7\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 3.5297431974351308\n",
      "step 8\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 4.345232684414773\n",
      "step 9\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 4.940129434083224\n",
      "step 10\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 5.675987615453556\n",
      "step 11\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 5.813771135218324\n",
      "step 12\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 5.902919922375893\n",
      "step 13\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 6.158513258453112\n",
      "step 14\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 7.079010483692887\n",
      "step 15\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 7.17638289534433\n",
      "step 16\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 8.024260328047882\n",
      "step 17\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 8.062436439210444\n",
      "step 18\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 8.328260864390659\n",
      "step 19\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 8.446654753073613\n",
      "step 20\n",
      "Observation [0.0, 0.0, 0.0]\n",
      "Action [0, 1]\n",
      "Reward 9.2340166656301\n",
      "Total reward got:9.2340\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = SampleEnvironment()\n",
    "    agent = Agent()\n",
    "    i = 0\n",
    "    while not env.is_done():\n",
    "        i += 1\n",
    "        print(\"step {}\".format(i))\n",
    "        agent.step(env)\n",
    "    print(\"Total reward got:%.4f\" % agent.total_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885ecfd-d541-4679-b36b-3a460fdae4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
